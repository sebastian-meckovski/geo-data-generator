{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 287,
   "id": "a54fdc5f-dbe6-4ce8-9bb0-04e1590ac82b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "languages = ['pl', 'lt', 'ru', 'hu', 'en', 'fr']\n",
    "\n",
    "global_cities_path = 'allCountries.txt'\n",
    "alternate_names_path = 'alternateNamesV2.txt'\n",
    "admin1_codes_path = 'admin1CodesASCII.txt'\n",
    "population_threshold = int(\"5000\")\n",
    "\n",
    "global_cities_headers = [\n",
    "    'geoname_id', 'name', 'ascii_name', 'alternate_names', 'latitude', 'longitude',\n",
    "    'feature_class', 'feature_code', 'country_code', 'cc2', 'admin1_code',\n",
    "    'admin2_code', 'admin3_code', 'admin4_code', 'population', 'elevation',\n",
    "    'dem', 'timezone', 'modification_date'\n",
    "]\n",
    "\n",
    "global_cities_headers_usecols = [\n",
    "    'geoname_id', 'name', 'ascii_name', 'latitude', 'longitude',\n",
    "    'feature_code', 'country_code', 'admin1_code', 'population'\n",
    "]\n",
    "\n",
    "# Define the data types for the columns in the global cities file\n",
    "global_cities_dtype = {\n",
    "    'geoname_id': 'Int64', 'name': str, 'ascii_name': str, 'alternatenames': str,\n",
    "    'latitude': float, 'longitude': float, 'feature_class': str, 'feature_code': str,\n",
    "    'country_code': str, 'cc2': str, 'admin1_code': str, 'admin2_code': str,\n",
    "    'admin3_code': str, 'admin4_code': str, 'population': 'Int64', 'elevation': float,\n",
    "    'dem': float, 'timezone': str, 'modification_date': str\n",
    "}\n",
    "\n",
    "# Define the column headers for the alternate names file\n",
    "alternate_names_headers = [\n",
    "    'alternate_name_id', 'geoname_id', 'iso_language', 'alternate_name',\n",
    "    'is_preferred_name', 'is_short_name', 'is_colloquial', 'is_historic', \n",
    "    'from', 'to'\n",
    "]\n",
    "\n",
    "alternate_names_headers_usecols = [\n",
    "    'geoname_id', 'iso_language', 'alternate_name',\n",
    "    'is_preferred_name', 'is_short_name', 'is_colloquial', 'is_historic'\n",
    "]\n",
    "\n",
    "alternate_names_dtype = {\n",
    "    'alternate_name_id': 'Int64', 'geoname_id': 'Int64', 'iso_language': str, 'alternate_name': str,\n",
    "    'is_preferred_name': 'boolean', 'is_short_name': 'boolean', 'is_colloquial': 'boolean', 'is_historic': 'boolean',\n",
    "    'from': str, 'to': str\n",
    "}\n",
    "\n",
    "admin1_codes_headers = [\n",
    "    'code', 'name', 'name_ascii', 'geoname_id_admin1'\n",
    "]\n",
    "\n",
    "admin1_codes_usecols = ['code', 'name', 'geoname_id_admin1', 'name_ascii']\n",
    "\n",
    "admin1_codes_dtype = {\n",
    "    'code': str, 'name': str, 'name_ascii': str, 'geoname_id_admin1': 'Int64'\n",
    "}\n",
    "\n",
    "alternate_names_df = pd.read_csv(alternate_names_path, sep='\\t', header=None, names=alternate_names_headers, dtype=alternate_names_dtype, low_memory=False, keep_default_na=False, na_values='', encoding='utf-8', usecols=alternate_names_headers_usecols)\n",
    "cities_df = pd.read_csv(global_cities_path, sep='\\t', header=None, names=global_cities_headers, dtype=global_cities_dtype, low_memory=False, keep_default_na=False, na_values='', encoding='utf-8', usecols=global_cities_headers_usecols)\n",
    "admin1_codes_df = pd.read_csv(admin1_codes_path, sep='\\t', header=None, names=admin1_codes_headers, dtype=admin1_codes_dtype, low_memory=False, keep_default_na=False, na_values='', encoding='utf-8', usecols=admin1_codes_usecols).rename(columns={\"name_ascii\": \"admin1_ascii_name\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "id": "75b6ae0b-9a7c-4810-b8e6-360a2aea72f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill <NA> values with False for the specified columns\n",
    "alternate_names_df[['is_preferred_name', 'is_short_name', 'is_colloquial', 'is_historic']] = \\\n",
    "    alternate_names_df[['is_preferred_name', 'is_short_name', 'is_colloquial', 'is_historic']].fillna(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "id": "c714898b-b6d3-4403-ab67-f0bcd7ae383e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate countries dataset\n",
    "countries_df = cities_df[cities_df['feature_code'].isin(['PCLI', 'PCLS', 'PCLIX', 'TERR', 'PCLD', 'PCL', 'PCLF'])].rename(columns={'name': 'name_country'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "id": "ea49b0a3-29cc-4c8a-b371-dba1ed154c47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "geoname_id      5589\n",
       "name            5589\n",
       "ascii_name      5589\n",
       "latitude        5589\n",
       "longitude       5589\n",
       "feature_code    5589\n",
       "country_code    5589\n",
       "admin1_code     5589\n",
       "population      5589\n",
       "dtype: int64"
      ]
     },
     "execution_count": 290,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_codes = [\n",
    "    'PPLA', 'PPLA2', 'PPLA3', 'PPLC', 'PPL', 'PPLW',\n",
    "    'PPLG', 'PPLL', 'PPLS', 'PPLF', 'PPLR'\n",
    "]\n",
    "\n",
    "filtered_cities_df = cities_df[cities_df['feature_code'].isin(feature_codes) & (cities_df['population'] >= population_threshold)]\n",
    "\n",
    "filtered_cities_df[filtered_cities_df['feature_code'] == 'PPLA3'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "id": "e376bd1c-48de-4d3a-8e7b-573d7ea3e954",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the DataFrames on the country code\n",
    "cities_with_country = pd.merge(filtered_cities_df, countries_df[['geoname_id', 'name_country', 'country_code', 'ascii_name']], on='country_code', how='left', suffixes=('_city', '_country'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "id": "70f57f97-c1dc-4af8-9922-3fe63e5fc6de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Include first-order administrative division in cities_with_country_table\n",
    "cities_with_country['admin1_geocode'] = cities_with_country['country_code'] + '.' + cities_with_country['admin1_code']\n",
    "\n",
    "cities_with_country_admin1_geocodes = pd.merge(cities_with_country, admin1_codes_df, right_on='code',\n",
    "                                               left_on='admin1_geocode', how='left',  suffixes=('_city', '_admin1')).drop('code', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "id": "9b032a27",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Sebastian\\Desktop\\geo-data-generator\\venv\\Lib\\site-packages\\geopandas\\geodataframe.py:1819: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  super().__setitem__(key, value)\n"
     ]
    }
   ],
   "source": [
    "import geohash\n",
    "\n",
    "def add_geohash(row):\n",
    "  \"\"\"Calculates the geohash for a given latitude and longitude.\"\"\"\n",
    "  return geohash.encode(row['latitude'], row['longitude'], precision=12)\n",
    "\n",
    "cities_with_country_admin1_geocodes['geohash'] = cities_with_country_admin1_geocodes.apply(add_geohash, axis=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "id": "82b7951b-52ef-4fed-86ca-760af3bff147",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Sebastian\\Desktop\\geo-data-generator\\venv\\Lib\\site-packages\\geopandas\\geodataframe.py:1819: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  super().__setitem__(key, value)\n"
     ]
    }
   ],
   "source": [
    "def calculate_radius(population):\n",
    "  if 0 <= population < 50000:\n",
    "    return 400\n",
    "  elif 50000 <= population < 100000:\n",
    "    return 800\n",
    "  elif 100000 <= population < 500000:\n",
    "    return 2000\n",
    "  elif 500000 <= population < 1000000:\n",
    "    return 4000\n",
    "  elif 1000000 <= population < 5000000:\n",
    "    return 12000\n",
    "  elif 5000000 <= population < 10000000:\n",
    "    return 15000\n",
    "  else: \n",
    "    return 18000\n",
    "\n",
    "cities_with_country_admin1_geocodes['estimated_radius'] = cities_with_country_admin1_geocodes['population'].apply(calculate_radius)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "id": "2a0531ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "from pyproj import CRS, Transformer\n",
    "from shapely.geometry import Point\n",
    "from shapely.ops import transform\n",
    "\n",
    "\n",
    "def geodesic_point_buffer(lat, lon, distance):\n",
    "    # Azimuthal equidistant projection\n",
    "    aeqd_proj = CRS.from_proj4(\n",
    "        f\"+proj=aeqd +lat_0={lat} +lon_0={lon} +x_0=0 +y_0=0\")\n",
    "    tfmr = Transformer.from_proj(aeqd_proj, aeqd_proj.geodetic_crs)\n",
    "    buf = Point(0, 0).buffer(distance)  # distance in metres\n",
    "    return transform(tfmr.transform, buf)\n",
    "\n",
    "points_df = cities_with_country_admin1_geocodes\n",
    "\n",
    "# Convert the points to circles by buffering them\n",
    "points_buffer_gdf = gpd.GeoDataFrame(\n",
    "    points_df,\n",
    "    geometry=points_df.apply(\n",
    "        lambda row : geodesic_point_buffer(row.latitude, row.longitude, row.estimated_radius), axis=1\n",
    "    ),\n",
    "    crs=4326,\n",
    ")\n",
    "\n",
    "# Determine the intersecting city buffers (result includes self-intersections)\n",
    "intersecting_gdf = points_buffer_gdf.sjoin(points_buffer_gdf)\n",
    "\n",
    "intersecting_larger_population_df = intersecting_gdf.loc[\n",
    "    (intersecting_gdf.population_left < intersecting_gdf.population_right) \n",
    "    & (intersecting_gdf.population_left < 2000000)  # New condition\n",
    "]\n",
    "\n",
    "# Remove the city buffers that intersect with a larger population city buffer\n",
    "cities_with_country_admin1_geocodes = points_buffer_gdf[\n",
    "    ~points_buffer_gdf.index.isin(intersecting_larger_population_df.index) \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "id": "ebb07236-c70e-4d0b-b985-9b61ea2be296",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved to combined_data.json\n"
     ]
    }
   ],
   "source": [
    "# Filter alternate_names_df for French names\n",
    "import json\n",
    "\n",
    "def determine_priority(row):\n",
    "    if row['is_preferred_name'] == True and row['is_short_name'] == False and row['is_colloquial'] == False and row['is_historic'] == False:\n",
    "        return 1\n",
    "    elif row['is_preferred_name'] == False and row['is_short_name'] == False and row['is_colloquial'] == False and row['is_historic'] == False:\n",
    "        return 2\n",
    "    elif row['is_preferred_name'] == False and row['is_short_name'] == True and row['is_colloquial'] == False and row['is_historic'] == False:\n",
    "        return 3\n",
    "    else:\n",
    "        return 4\n",
    "    \n",
    "def check_names_city_country(row):\n",
    "    name = str(row['ascii_name_city']).lower().strip()\n",
    "    country = str(row['ascii_name_country']).lower().strip()\n",
    "    return country in name or name in country\n",
    "\n",
    "def check_names_city_admin1(row):\n",
    "    name = str(row['ascii_name_city']).lower().strip()\n",
    "    admin1 = str(row['admin1_ascii_name']).lower().strip()\n",
    "    return name in admin1 or admin1 in name\n",
    "\n",
    "def check_names_admin1_country(row):\n",
    "    country = str(row['ascii_name_country']).lower().strip()\n",
    "    admin1 = str(row['admin1_ascii_name']).lower().strip()\n",
    "    return country in admin1 or admin1 in country\n",
    "\n",
    "def remove_redundant_admin1(df):\n",
    "    \"\"\"\n",
    "    Removes admin1 information (name_admin1 and admin1_ascii_name) \n",
    "    if the ASCII city name is unique within its country.\n",
    "\n",
    "    Args:\n",
    "      df: The GeoDataFrame containing city information.\n",
    "\n",
    "    Returns:\n",
    "      The modified GeoDataFrame.\n",
    "    \"\"\"\n",
    "\n",
    "    df = df.copy()  # Create a copy to avoid SettingWithCopyWarning\n",
    "\n",
    "    # Calculate the count of cities with the same ASCII name within each country\n",
    "    df[\"city_count\"] = df.groupby([\"geoname_id_country\", \"ascii_name_city\"])[\"geoname_id_city\"].transform(\"count\")\n",
    "    # Set name_admin1 and admin1_ascii_name to NaN where city_count is 1\n",
    "    df.loc[df[\"city_count\"] == 1, [\"alternate_name_admin1\", \"admin1_ascii_name\"]] = np.nan\n",
    "    # Calculate the count of cities with the same name within each country\n",
    "    df[\"city_count\"] = df.groupby([\"geoname_id_country\", \"name_city\"])[\"geoname_id_city\"].transform(\"count\")\n",
    "    # Set name_admin1 and admin1_ascii_name to NaN where city_count is 1\n",
    "    df.loc[df[\"city_count\"] == 1, [\"alternate_name_admin1\", \"admin1_ascii_name\"]] = np.nan\n",
    "\n",
    "    return df\n",
    "\n",
    "# Initialize an empty dictionary to store the combined data\n",
    "combined_data = {}\n",
    "\n",
    "for language in languages:\n",
    "    filtered_alternate_names = alternate_names_df[alternate_names_df['iso_language'] == language].copy()\n",
    "    filtered_alternate_names['priority'] = filtered_alternate_names.apply(determine_priority, axis=1)\n",
    "    filtered_alternate_names.sort_values(by=['priority', 'geoname_id'], inplace=True)\n",
    "    filtered_alternate_names = filtered_alternate_names.groupby('geoname_id').first().reset_index()\n",
    "\n",
    "    cities_with_country_admin1_alternates = pd.merge(cities_with_country_admin1_geocodes, filtered_alternate_names[['geoname_id', 'alternate_name']], \n",
    "                                                     how='left', left_on='geoname_id_city', right_on='geoname_id').drop('geoname_id', axis=1)\n",
    "    \n",
    "    cities_with_country_admin1_alternates['alternate_name'] = cities_with_country_admin1_alternates['alternate_name'].fillna(\n",
    "        cities_with_country_admin1_alternates['ascii_name_city']\n",
    "    )\n",
    "\n",
    "    cities_with_country_admin1_alternates = pd.merge(cities_with_country_admin1_alternates, filtered_alternate_names[['geoname_id', 'alternate_name']], \n",
    "                                                     how='left', left_on='geoname_id_admin1', right_on='geoname_id', suffixes=('_city','_admin1')).drop('geoname_id', axis=1)\n",
    "    \n",
    "    cities_with_country_admin1_alternates['alternate_name_admin1'] = cities_with_country_admin1_alternates['alternate_name_admin1'].fillna(\n",
    "        cities_with_country_admin1_alternates['admin1_ascii_name']\n",
    "    )\n",
    "\n",
    "    cities_with_country_admin1_alternates = remove_redundant_admin1(cities_with_country_admin1_alternates)\n",
    "\n",
    "    cities_with_country_admin1_alternates = pd.merge(cities_with_country_admin1_alternates, filtered_alternate_names[['geoname_id', 'alternate_name']], \n",
    "                                                     how='left', left_on='geoname_id_country', right_on='geoname_id').drop('geoname_id', axis=1).rename(columns={'alternate_name': 'alternate_name_country'})\n",
    "                                                     \n",
    "    cities_with_country_admin1_alternates['alternate_name_country'] = cities_with_country_admin1_alternates['alternate_name_country'].fillna(\n",
    "        cities_with_country_admin1_alternates['name_country']\n",
    "    )\n",
    "\n",
    "    country_names_indices_to_remove = cities_with_country_admin1_alternates[\n",
    "        cities_with_country_admin1_alternates.apply(check_names_city_country, axis=1)\n",
    "    ].index\n",
    "    cities_with_country_admin1_alternates.loc[country_names_indices_to_remove, 'alternate_name_country'] = np.nan\n",
    "\n",
    "    admin1_names_indices_to_remove = cities_with_country_admin1_alternates[\n",
    "        cities_with_country_admin1_alternates.apply(check_names_city_admin1, axis=1)\n",
    "    ].index \n",
    "\n",
    "    cities_with_country_admin1_alternates.loc[admin1_names_indices_to_remove, 'alternate_name_admin1'] = np.nan\n",
    "\n",
    "    admin1_names_vs_country_indices_to_remove = cities_with_country_admin1_alternates[\n",
    "        cities_with_country_admin1_alternates.apply(check_names_admin1_country, axis=1)\n",
    "    ].index \n",
    "    cities_with_country_admin1_alternates.loc[admin1_names_vs_country_indices_to_remove, 'alternate_name_admin1'] = np.nan\n",
    "\n",
    "    # Iterate through the rows and update the combined_data dictionary\n",
    "    for _, row in cities_with_country_admin1_alternates.iterrows():\n",
    "        geoname_id_city = row['geoname_id_city']\n",
    "        if geoname_id_city not in combined_data:\n",
    "            combined_data[geoname_id_city] = {\n",
    "                'geoname_id_city': geoname_id_city,\n",
    "                'latitude': row['latitude'],\n",
    "                'longitude': row['longitude'],\n",
    "                'geohash': row['geohash'],\n",
    "                'country_code': row['country_code'],\n",
    "                'population': row['population'],\n",
    "                'estimated_radius': row['estimated_radius'],\n",
    "                'feature_code': row['feature_code'],\n",
    "                'name': {}\n",
    "            }\n",
    "        combined_data[geoname_id_city]['name'][language] = {\n",
    "            'city': row['alternate_name_city'] if pd.notna(row['alternate_name_city']) else None,\n",
    "            'admin1': row['alternate_name_admin1'] if pd.notna(row['alternate_name_admin1']) else None,\n",
    "            'country': row['alternate_name_country'] if pd.notna(row['alternate_name_country']) else None\n",
    "        }\n",
    "        combined_data[geoname_id_city]['name']['ascii'] = {\n",
    "            'city': row['ascii_name_city'].lower().replace(\" \", \"-\") if pd.notna(row['ascii_name_city']) else None,\n",
    "            'admin1': row['admin1_ascii_name'].lower().replace(\" \", \"-\") if pd.notna(row['admin1_ascii_name']) else None,\n",
    "            'country': None\n",
    "        }\n",
    "\n",
    "# Convert the combined_data dictionary to a list\n",
    "nested_json_list = list(combined_data.values())\n",
    "\n",
    "# Save the nested JSON to a file\n",
    "with open('combined_data.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(nested_json_list, f, ensure_ascii=False, indent=4)\n",
    "\n",
    "print(\"Data saved to combined_data.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "id": "d67eb7fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>geoname_id_city</th>\n",
       "      <th>name_city</th>\n",
       "      <th>ascii_name_city</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>feature_code</th>\n",
       "      <th>country_code</th>\n",
       "      <th>admin1_code</th>\n",
       "      <th>population</th>\n",
       "      <th>geoname_id_country</th>\n",
       "      <th>...</th>\n",
       "      <th>name_admin1</th>\n",
       "      <th>admin1_ascii_name</th>\n",
       "      <th>geoname_id_admin1</th>\n",
       "      <th>geohash</th>\n",
       "      <th>estimated_radius</th>\n",
       "      <th>geometry</th>\n",
       "      <th>alternate_name_city</th>\n",
       "      <th>alternate_name_admin1</th>\n",
       "      <th>city_count</th>\n",
       "      <th>alternate_name_country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3039163</td>\n",
       "      <td>Sant Julià de Lòria</td>\n",
       "      <td>Sant Julia de Loria</td>\n",
       "      <td>42.46372</td>\n",
       "      <td>1.49129</td>\n",
       "      <td>PPLA</td>\n",
       "      <td>AD</td>\n",
       "      <td>06</td>\n",
       "      <td>8022</td>\n",
       "      <td>3041565</td>\n",
       "      <td>...</td>\n",
       "      <td>Sant Julià de Loria</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3039162</td>\n",
       "      <td>sp919fmcje4k</td>\n",
       "      <td>400</td>\n",
       "      <td>POLYGON ((1.49615 42.46372, 1.49613 42.46337, ...</td>\n",
       "      <td>Sant Julià de Lòria</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>Andorre</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3040051</td>\n",
       "      <td>les Escaldes</td>\n",
       "      <td>les Escaldes</td>\n",
       "      <td>42.50729</td>\n",
       "      <td>1.53414</td>\n",
       "      <td>PPLA</td>\n",
       "      <td>AD</td>\n",
       "      <td>08</td>\n",
       "      <td>15853</td>\n",
       "      <td>3041565</td>\n",
       "      <td>...</td>\n",
       "      <td>Escaldes-Engordany</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3338529</td>\n",
       "      <td>sp91ffjnuj1t</td>\n",
       "      <td>400</td>\n",
       "      <td>POLYGON ((1.53901 42.50729, 1.53898 42.50694, ...</td>\n",
       "      <td>Escaldes-Engordany</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>Andorre</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3040132</td>\n",
       "      <td>la Massana</td>\n",
       "      <td>la Massana</td>\n",
       "      <td>42.54499</td>\n",
       "      <td>1.51483</td>\n",
       "      <td>PPLA</td>\n",
       "      <td>AD</td>\n",
       "      <td>04</td>\n",
       "      <td>7211</td>\n",
       "      <td>3041565</td>\n",
       "      <td>...</td>\n",
       "      <td>La Massana</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3040131</td>\n",
       "      <td>sp9443p4d0gn</td>\n",
       "      <td>400</td>\n",
       "      <td>POLYGON ((1.5197 42.54499, 1.51968 42.54464, 1...</td>\n",
       "      <td>La Massana</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>Andorre</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3040686</td>\n",
       "      <td>Encamp</td>\n",
       "      <td>Encamp</td>\n",
       "      <td>42.53474</td>\n",
       "      <td>1.58014</td>\n",
       "      <td>PPLA</td>\n",
       "      <td>AD</td>\n",
       "      <td>03</td>\n",
       "      <td>11223</td>\n",
       "      <td>3041565</td>\n",
       "      <td>...</td>\n",
       "      <td>Encamp</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3040684</td>\n",
       "      <td>sp91gznwgfjz</td>\n",
       "      <td>400</td>\n",
       "      <td>POLYGON ((1.58501 42.53474, 1.58499 42.53439, ...</td>\n",
       "      <td>Encamp</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>Andorre</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3041563</td>\n",
       "      <td>Andorra la Vella</td>\n",
       "      <td>Andorra la Vella</td>\n",
       "      <td>42.50779</td>\n",
       "      <td>1.52109</td>\n",
       "      <td>PPLC</td>\n",
       "      <td>AD</td>\n",
       "      <td>07</td>\n",
       "      <td>20430</td>\n",
       "      <td>3041565</td>\n",
       "      <td>...</td>\n",
       "      <td>Andorra la Vella</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3041566</td>\n",
       "      <td>sp91fd79gfqu</td>\n",
       "      <td>400</td>\n",
       "      <td>POLYGON ((1.52596 42.50779, 1.52593 42.50744, ...</td>\n",
       "      <td>Andorre-la-Vieille</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>Andorre</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   geoname_id_city            name_city      ascii_name_city  latitude  \\\n",
       "0          3039163  Sant Julià de Lòria  Sant Julia de Loria  42.46372   \n",
       "1          3040051         les Escaldes         les Escaldes  42.50729   \n",
       "2          3040132           la Massana           la Massana  42.54499   \n",
       "3          3040686               Encamp               Encamp  42.53474   \n",
       "4          3041563     Andorra la Vella     Andorra la Vella  42.50779   \n",
       "\n",
       "   longitude feature_code country_code admin1_code  population  \\\n",
       "0    1.49129         PPLA           AD          06        8022   \n",
       "1    1.53414         PPLA           AD          08       15853   \n",
       "2    1.51483         PPLA           AD          04        7211   \n",
       "3    1.58014         PPLA           AD          03       11223   \n",
       "4    1.52109         PPLC           AD          07       20430   \n",
       "\n",
       "   geoname_id_country  ...          name_admin1 admin1_ascii_name  \\\n",
       "0             3041565  ...  Sant Julià de Loria               NaN   \n",
       "1             3041565  ...   Escaldes-Engordany               NaN   \n",
       "2             3041565  ...           La Massana               NaN   \n",
       "3             3041565  ...               Encamp               NaN   \n",
       "4             3041565  ...     Andorra la Vella               NaN   \n",
       "\n",
       "  geoname_id_admin1       geohash estimated_radius  \\\n",
       "0           3039162  sp919fmcje4k              400   \n",
       "1           3338529  sp91ffjnuj1t              400   \n",
       "2           3040131  sp9443p4d0gn              400   \n",
       "3           3040684  sp91gznwgfjz              400   \n",
       "4           3041566  sp91fd79gfqu              400   \n",
       "\n",
       "                                            geometry  alternate_name_city  \\\n",
       "0  POLYGON ((1.49615 42.46372, 1.49613 42.46337, ...  Sant Julià de Lòria   \n",
       "1  POLYGON ((1.53901 42.50729, 1.53898 42.50694, ...   Escaldes-Engordany   \n",
       "2  POLYGON ((1.5197 42.54499, 1.51968 42.54464, 1...           La Massana   \n",
       "3  POLYGON ((1.58501 42.53474, 1.58499 42.53439, ...               Encamp   \n",
       "4  POLYGON ((1.52596 42.50779, 1.52593 42.50744, ...   Andorre-la-Vieille   \n",
       "\n",
       "   alternate_name_admin1 city_count alternate_name_country  \n",
       "0                    NaN          1                Andorre  \n",
       "1                    NaN          1                Andorre  \n",
       "2                    NaN          1                Andorre  \n",
       "3                    NaN          1                Andorre  \n",
       "4                    NaN          1                Andorre  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 300,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cities_with_country_admin1_alternates.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "id": "4508a051",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import folium\n",
    "\n",
    "# def create_popup_content(row):\n",
    "#     popup_content = \"\"\n",
    "#     if not pd.isna(row['name_city']):\n",
    "#         popup_content += f\"{row['name_city']}, \"\n",
    "#     # if not pd.isna(row['alternate_name_admin1']):\n",
    "#     #     popup_content += f\"{row['alternate_name_admin1']}, \"\n",
    "#     # if not pd.isna(row['alternate_name_country']):\n",
    "#     #     popup_content += f\"{row['alternate_name_country']}, \"\n",
    "#     # if not pd.isna(row['feature_code']):\n",
    "#     #     popup_content += f\"{row['feature_code']}, \" \n",
    "    \n",
    "#     # Format population with commas\n",
    "#     popup_content += f\"Population: {int(row['population']):,}, \"  \n",
    "\n",
    "#     # Add radius\n",
    "#     radius = calculate_radius(row['population'])\n",
    "#     # Format radius with commas\n",
    "#     popup_content += f\"Radius: {radius:,} meters\"  \n",
    "\n",
    "#     return popup_content.rstrip(\", \")  # Remove trailing comma and space\n",
    "\n",
    "# # Create a map centered on a specific location\n",
    "# m = folium.Map(location=[47.4979, 19.0402], zoom_start=10)  # Centered on Budapest\n",
    "\n",
    "# # Add markers with circles for each city\n",
    "# for index, row in cities_with_country_admin1_geocodes.iterrows():\n",
    "#     folium.Circle(\n",
    "#         location=[row['latitude'], row['longitude']],\n",
    "#         radius=row['estimated_radius'],  # Example radius in meters\n",
    "#         popup=create_popup_content(row),\n",
    "#         color=\"blue\",\n",
    "#         fill=True,\n",
    "#         fill_color=\"blue\"\n",
    "#     ).add_to(m)\n",
    "\n",
    "# # Save the map as an HTML file\n",
    "# m.save(\"cities_map.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60fc403c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
