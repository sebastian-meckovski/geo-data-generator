{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "a54fdc5f-dbe6-4ce8-9bb0-04e1590ac82b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Define the file paths\n",
    "global_cities_path = 'allCountries.txt'\n",
    "alternate_names_path = 'alternateNamesV2.txt'\n",
    "admin1_codes_path = 'admin1CodesASCII.txt'\n",
    "\n",
    "# Define the column headers for the global cities file\n",
    "global_cities_headers = [\n",
    "    'geoname_id', 'name', 'ascii_name', 'alternate_names', 'latitude', 'longitude',\n",
    "    'feature_class', 'feature_code', 'country_code', 'cc2', 'admin1_code',\n",
    "    'admin2_code', 'admin3_code', 'admin4_code', 'population', 'elevation',\n",
    "    'dem', 'timezone', 'modification_date'\n",
    "]\n",
    "\n",
    "# Define the data types for the columns in the global cities file\n",
    "global_cities_dtype = {\n",
    "    'geoname_id': int, 'name': str, 'asciiname': str, 'alternatenames': str,\n",
    "    'latitude': float, 'longitude': float, 'feature_class': str, 'feature_code': str,\n",
    "    'country_code': str, 'cc2': str, 'admin1_code': str, 'admin2_code': str,\n",
    "    'admin3_code': str, 'admin4_code': str, 'population': float, 'elevation': float,\n",
    "    'dem': float, 'timezone': str, 'modification_date': str\n",
    "}\n",
    "\n",
    "# Define the column headers for the alternate names file\n",
    "alternate_names_headers = [\n",
    "    'alternate_name_id', 'geoname_id', 'iso_language', 'alternate_name',\n",
    "    'is_preferred_name', 'is_short_name', 'is_colloquial', 'is_historic', \n",
    "    'from', 'to'\n",
    "]\n",
    "\n",
    "# Define the data types for the columns in the alternate names file\n",
    "alternate_names_dtype = {\n",
    "    'alternate_name_id': int, 'geoname_id': int, 'iso_language': str, 'alternate_name': str,\n",
    "    'is_preferred_name': 'boolean', 'is_short_name': 'boolean', 'is_colloquial': 'boolean', 'is_historic': 'boolean',\n",
    "    'from': str, 'to': str\n",
    "}\n",
    "\n",
    "# Define the column headers for the admin1 codes file\n",
    "admin1_codes_headers = [\n",
    "    'code', 'name', 'name_ascii', 'geoname_id'\n",
    "]\n",
    "\n",
    "# Define the data types for the columns in the admin1 codes file\n",
    "admin1_codes_dtype = {\n",
    "    'code': str, 'name': str, 'name_ascii': str, 'geoname_id': int\n",
    "}\n",
    "\n",
    "# Read the files into pandas DataFrames\n",
    "alternate_names_df = pd.read_csv(alternate_names_path, sep='\\t', header=None, names=alternate_names_headers, dtype=alternate_names_dtype, low_memory=False, keep_default_na=False, na_values='')\n",
    "cities_df = pd.read_csv(global_cities_path, sep='\\t', header=None, names=global_cities_headers, dtype=global_cities_dtype, low_memory=False, keep_default_na=False, na_values='')\n",
    "admin1_codes_df = pd.read_csv(admin1_codes_path, sep='\\t', header=None, names=admin1_codes_headers, dtype=admin1_codes_dtype, low_memory=False, keep_default_na=False, na_values='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "75b6ae0b-9a7c-4810-b8e6-360a2aea72f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill <NA> values with False for the specified columns\n",
    "alternate_names_df[['is_preferred_name', 'is_short_name', 'is_colloquial', 'is_historic']] = \\\n",
    "    alternate_names_df[['is_preferred_name', 'is_short_name', 'is_colloquial', 'is_historic']].fillna(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "c714898b-b6d3-4403-ab67-f0bcd7ae383e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate countries dataset\n",
    "countries_df = cities_df[cities_df['feature_code'].isin(['PCLI', 'PCLS', 'PCLIX', 'TERR', 'PCLD', 'PCL', 'PCLF'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "ea49b0a3-29cc-4c8a-b371-dba1ed154c47",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_codes = [\n",
    "    'PPLA', 'PPLC', 'PPL', 'PPLW',\n",
    "    'PPLG', 'PPLL', 'PPLS', 'PPLF', 'PPLR'\n",
    "]\n",
    "\n",
    "filtered_cities_df = cities_df[cities_df['feature_code'].isin(feature_codes) & (cities_df['population'] >= 15000)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "e376bd1c-48de-4d3a-8e7b-573d7ea3e954",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the DataFrames on the country code\n",
    "cities_with_country = pd.merge(filtered_cities_df, countries_df[['geoname_id', 'country_code']], on='country_code', how='left')\n",
    "\n",
    "# Rename the 'geoname_id_x' column from countries_df to 'geoname_id'\n",
    "cities_with_country = cities_with_country.rename(columns={'geoname_id_x': 'geoname_id'})\n",
    "\n",
    "# Rename the 'geoname_id' column from countries_df to 'country_geoname_id'\n",
    "cities_with_country = cities_with_country.rename(columns={'geoname_id_y': 'country_geoname_id'})\n",
    "\n",
    "# Drop rows with NaN values in 'country_geoname_id'\n",
    "cities_with_country.dropna(subset=['country_geoname_id'], inplace=True)\n",
    "\n",
    "# Now it's safe to convert to integer\n",
    "cities_with_country['country_geoname_id'] = cities_with_country['country_geoname_id'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "ebb07236-c70e-4d0b-b985-9b61ea2be296",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter alternate_names_df for French names\n",
    "filtered_alternate_names = alternate_names_df[alternate_names_df['iso_language'] == 'fr'].copy()\n",
    "\n",
    "def determine_priority(row):\n",
    "    if row['is_preferred_name'] == True and row['is_short_name'] == False and row['is_colloquial'] == False and row['is_historic'] == False:\n",
    "        return 1\n",
    "    elif row['is_preferred_name'] == False and row['is_short_name'] == False and row['is_colloquial'] == False and row['is_historic'] == False:\n",
    "        return 2\n",
    "    elif row['is_preferred_name'] == False and row['is_short_name'] == True and row['is_colloquial'] == False and row['is_historic'] == False:\n",
    "        return 3\n",
    "    else:\n",
    "        return 4\n",
    "\n",
    "# Add a priority column to the filtered DataFrame\n",
    "filtered_alternate_names['priority'] = filtered_alternate_names.apply(determine_priority, axis=1)\n",
    "\n",
    "# Sort the filtered DataFrame by priority and geoname_id\n",
    "filtered_alternate_names.sort_values(by=['priority', 'geoname_id'], inplace=True)\n",
    "\n",
    "# Select the first row for each geoname_id in the filtered DataFrame\n",
    "filtered_alternate_names = filtered_alternate_names.groupby('geoname_id').first().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbb28de7-114c-457e-9ea6-a94d33b3c4f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfb45419-20f1-486a-ab63-5df48fa071fe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
